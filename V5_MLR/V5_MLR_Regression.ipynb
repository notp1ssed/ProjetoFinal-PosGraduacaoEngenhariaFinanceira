{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacao das libraries\n",
    "import pandas as pd\n",
    "import functions as main\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"df_lagged_weekly\"\n",
    "\n",
    "opencsv = pd.read_csv(rf\"D:\\OneDrive - Instituto Politecnico de Castelo Branco\\002_Learning\\001_Pos_Graduacao\\Ciclo 5 - Projeto Final\\ProjetoFinal-PosGraduacaoEngenhariaFinanceira\\{csv}.csv\", sep=\",\")\n",
    "opencsv.set_index('Date', inplace=True)\n",
    "opencsv.index = pd.to_datetime(opencsv.index)\n",
    "opencsv = opencsv.asfreq(pd.infer_freq(opencsv.index))\n",
    "opencsv = opencsv.astype(float)\n",
    "opencsv = opencsv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = opencsv.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1_BTC_Supply                  0\n",
       "L1_BalanceSheet_FED            0\n",
       "L1_BalanceSheet_global         0\n",
       "L1_Bitcoin_Wikipedia_Search    0\n",
       "L1_Dollar_Index                0\n",
       "L1_GLD                         0\n",
       "L1_HashRate                    0\n",
       "L1_M2_Liquidity                0\n",
       "L1_Miners_Revenue_USD          0\n",
       "L1_Mining_Difficulty           0\n",
       "L1_Nr_Addresses                0\n",
       "L1_Nr_Transactions             0\n",
       "L1_OIL_USD                     0\n",
       "L1_QQQ                         0\n",
       "L1_TLT                         0\n",
       "L1_Ten_YR_USA                  0\n",
       "L1_USD_OnChain_Volume          0\n",
       "L1_VIX                         0\n",
       "BTC_USD                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção de Variáveis\n",
    "\n",
    "Considerar técnicas como regressão lasso, ridge ou elastic net, que fazem seleção de variáveis automaticamente, pode ser útil se você suspeitar que nem todas as 20 variáveis são relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Hipoteses a testar</b>\n",
    "\n",
    "H1: Ceteris paribus, Bitcoin é um ativo de especulação.\n",
    "\n",
    "H2: Ceteris paribus, a performance de Bitcoin é influenciada por fatores macroeconómicos.\n",
    "\n",
    "H3: Ceteris paribus, quanto mais liquidez há no mercado, maior é a apreciação de preço de Bitcoin.\n",
    "\n",
    "H4: Ceteris paribus, os fatores endógenos de Bitcoin são os maiores explicadores da performance de Bitcoin.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L1_BTC_Supply', 'L1_BalanceSheet_FED', 'L1_BalanceSheet_global',\n",
       "       'L1_Bitcoin_Wikipedia_Search', 'L1_Dollar_Index', 'L1_GLD',\n",
       "       'L1_HashRate', 'L1_M2_Liquidity', 'L1_Miners_Revenue_USD',\n",
       "       'L1_Mining_Difficulty', 'L1_Nr_Addresses', 'L1_Nr_Transactions',\n",
       "       'L1_OIL_USD', 'L1_QQQ', 'L1_TLT', 'L1_Ten_YR_USA',\n",
       "       'L1_USD_OnChain_Volume', 'L1_VIX', 'BTC_USD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressao Linear Multipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                BTC_USD   R-squared:                       0.933\n",
      "Model:                            OLS   Adj. R-squared:                  0.933\n",
      "Method:                 Least Squares   F-statistic:                     3911.\n",
      "Date:                Thu, 29 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        23:01:51   Log-Likelihood:                -251.37\n",
      "No. Observations:                 705   AIC:                             510.7\n",
      "Df Residuals:                     701   BIC:                             529.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:                  HC3                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                -25.1116      5.497     -4.568      0.000     -35.886     -14.337\n",
      "L1_Nr_Transactions    -0.4166      0.124     -3.355      0.001      -0.660      -0.173\n",
      "L1_HashRate            0.3579      0.024     14.793      0.000       0.310       0.405\n",
      "L1_BTC_Supply          3.9416      0.859      4.591      0.000       2.259       5.624\n",
      "==============================================================================\n",
      "Omnibus:                       19.690   Durbin-Watson:                   0.043\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               13.965\n",
      "Skew:                           0.231   Prob(JB):                     0.000928\n",
      "Kurtosis:                       2.488   Cond. No.                     3.53e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC3)\n",
      "[2] The condition number is large, 3.53e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Yt = b0 + b1X1t + b2X2t + εt\n",
    "\n",
    "\n",
    "# Modelos endogenos Bitcoin\n",
    "# 'L1.BTC_Supply', 'L1.Bitcoin_Wikipedia_Search', 'L1.HashRate', 'L1.Miners_Revenue_USD', \n",
    "# 'L1.Mining_Difficulty', 'L1.Nr_Addresses', 'L1.Nr_Transactions', 'L1.Nr_Tx_Block', 'L1.USD_OnChain_Volume'\n",
    "model1a = [ 'L1_Bitcoin_Wikipedia_Search', 'L1_Miners_Revenue_USD', 'L1_Mining_Difficulty', 'L1_USD_OnChain_Volume'] # 'L1.Nr_Addresses', 'L1.Nr_Transactions'\n",
    "model1b = [ 'L1_Nr_Transactions', 'L1_HashRate', 'L1_BTC_Supply', ] # 'L1.Nr_Addresses', 'L1.Nr_Transactions'\n",
    "\n",
    "\n",
    "# Modelos Macro Economicos\n",
    "# 'L1.10YR_USA', 'L1.BalanceSheet_FED', 'L1.BalanceSheet_global', 'L1.Dollar_Index', \n",
    "# 'L1.GLD', 'L1.M2_Liquidity', 'L1.OIL_USD', 'L1.QQQ', 'L1.TLT', 'L1.VIX'\n",
    "\n",
    "model2a = [ ]\n",
    "model2b = [ ]\n",
    "\n",
    "# Modelos Gerais\n",
    "model3a = [  ]\n",
    "model3b = [  ]\n",
    "\n",
    "\n",
    "\n",
    "X = df_model[model1b]\n",
    "y = df_model[\"BTC_USD\"]\n",
    "\n",
    "X = sm.add_constant(X) # Add a constant term to the predictors\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "# robust regression -> model.fit( cov_type = \"HC3\" ) \n",
    "\n",
    "results = model.fit( cov_type = \"HC3\" ) # Fit the OLS model \n",
    "\n",
    "print(results.summary()) # Print the summary of the regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Wise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, endog, exg):\n",
    "    '''\n",
    "    Linear model designed by forward selection based on p-values.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : Pandas DataFrame with dependent and independent variables\n",
    "    endog: string literals, dependent variable from the data\n",
    "    exg: string literals, independent variable from the data\n",
    "    Returns:\n",
    "    --------\n",
    "    res : an \"optimal\" fitted Statsmodels linear model instance\n",
    "    with an intercept selected by forward selection\n",
    "    '''\n",
    "    remaining = set(data.columns)\n",
    "    remaining = [e for e in remaining if (e not in endog)&(e not in exg)]\n",
    "    exg = [exg]\n",
    "\n",
    "    scores_with_candidates = []\n",
    "    for candidate in remaining:\n",
    "        formula = '{} ~ {}'.format(endog,' + '.join(exg + [candidate]))\n",
    "        score = smf.ols(formula, data).fit(cov_type = \"HC3\").pvalues[2]\n",
    "        scores_with_candidates.append((score, candidate))\n",
    "    scores_with_candidates.sort()\n",
    "\n",
    "    for pval,candidate in scores_with_candidates:\n",
    "        if pval < 0.1:\n",
    "            exg.append(candidate)\n",
    "    \n",
    "    formula = '{} ~ {}'.format(endog, ' + '.join(exg))\n",
    "    res = smf.ols(formula, data).fit()\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = forward_selected(data = df_model, endog = 'BTC_USD', exg = 'L1_Nr_Addresses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC_USD ~ L1_Nr_Addresses + L1_Miners_Revenue_USD + L1_QQQ + L1_M2_Liquidity + L1_BalanceSheet_global + L1_USD_OnChain_Volume + L1_GLD + L1_BalanceSheet_FED + L1_HashRate + L1_Mining_Difficulty + L1_OIL_USD + L1_BTC_Supply + L1_Ten_YR_USA + L1_VIX + L1_Bitcoin_Wikipedia_Search + L1_Nr_Transactions\n"
     ]
    }
   ],
   "source": [
    "print(res.model.formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                BTC_USD   R-squared:                       0.995\n",
      "Model:                            OLS   Adj. R-squared:                  0.994\n",
      "Method:                 Least Squares   F-statistic:                     7896.\n",
      "Date:                Thu, 29 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        23:01:18   Log-Likelihood:                 634.36\n",
      "No. Observations:                 705   AIC:                            -1235.\n",
      "Df Residuals:                     688   BIC:                            -1157.\n",
      "Df Model:                          16                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      -2.4418      2.103     -1.161      0.246      -6.571       1.687\n",
      "L1_Nr_Addresses                -0.5052      0.082     -6.175      0.000      -0.666      -0.345\n",
      "L1_Miners_Revenue_USD           0.6476      0.030     21.426      0.000       0.588       0.707\n",
      "L1_QQQ                          0.1975      0.144      1.372      0.170      -0.085       0.480\n",
      "L1_M2_Liquidity                 3.9368      0.516      7.636      0.000       2.925       4.949\n",
      "L1_BalanceSheet_global         -2.0896      0.916     -2.280      0.023      -3.889      -0.290\n",
      "L1_USD_OnChain_Volume           0.2004      0.027      7.528      0.000       0.148       0.253\n",
      "L1_GLD                         -0.4806      0.134     -3.600      0.000      -0.743      -0.218\n",
      "L1_BalanceSheet_FED            -0.1142      0.158     -0.723      0.470      -0.425       0.196\n",
      "L1_HashRate                     0.0483      0.080      0.606      0.545      -0.108       0.205\n",
      "L1_Mining_Difficulty            0.0866      0.080      1.087      0.277      -0.070       0.243\n",
      "L1_OIL_USD                      0.2144      0.069      3.093      0.002       0.078       0.350\n",
      "L1_BTC_Supply                  -1.0496      0.259     -4.054      0.000      -1.558      -0.541\n",
      "L1_Ten_YR_USA                  -0.1636      0.045     -3.642      0.000      -0.252      -0.075\n",
      "L1_VIX                         -0.1859      0.045     -4.107      0.000      -0.275      -0.097\n",
      "L1_Bitcoin_Wikipedia_Search     0.1355      0.027      5.084      0.000       0.083       0.188\n",
      "L1_Nr_Transactions              0.3762      0.067      5.625      0.000       0.245       0.507\n",
      "==============================================================================\n",
      "Omnibus:                      102.360   Durbin-Watson:                   0.812\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              849.169\n",
      "Skew:                          -0.336   Prob(JB):                    4.03e-185\n",
      "Kurtosis:                       8.334   Cond. No.                     1.32e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.32e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto run Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_columns = ['model_1a', 'model_1b'] # , 'model_1c', 'model_2a', 'model_2b', 'model_2c', 'model_2d', 'model_3a', 'model_3b', 'model_3c'\n",
    "\n",
    "def run_models_stats(df, models_list, y):\n",
    "        count = 0\n",
    "        for model_columns in models_list:\n",
    "            X = df[model_columns]\n",
    "\n",
    "            X = sm.add_constant(X)  # Add a constant term to the predictors\n",
    "\n",
    "            model = sm.OLS(y, X)\n",
    "            results = model.fit()  # Fit the OLS model\n",
    "            \n",
    "            print(\"\\n####################################################################################################### \\n\\n\")\n",
    "            print(\"\\nModel:\", models_columns[count]) # columns name\n",
    "            #print(\"Variable:\", results.params.index) # set as index\n",
    "            print(f\"\\nCoeff: {results.params}\") # coefficients\n",
    "            print(\"\\nP-Value:\", results.pvalues) # p-values\n",
    "            print(\"\\nR-Squared:\", results.rsquared_adj)\n",
    "            print(\"No. Obs.:\", results.nobs)\n",
    "            print(\"Cond. no.:\", results.condition_number)\n",
    "            count += 1\n",
    "            print(\"\\n####################################################################################################### \\n\\n\")\n",
    "\n",
    "\n",
    "def run_models(df, models_list, y):\n",
    "    f = open(f\"MLR_Results_Ciclo{ciclo}.txt\", \"w\")\n",
    "    count = 0\n",
    "    for model_columns in models_list:\n",
    "        X = df[model_columns]\n",
    "\n",
    "        X = sm.add_constant(X)  # Add a constant term to the predictors\n",
    "\n",
    "        model = sm.OLS(y, X)\n",
    "        results = model.fit()  # Fit the OLS model\n",
    "        \n",
    "        f.write(\"\\n####################################################################################################### \\n\\n\")\n",
    "        f.write(models_columns[count])\n",
    "        f.write(\" \\n\")\n",
    "        f.write(f\"{results.summary()}\")\n",
    "        count += 1\n",
    "        f.write(\"\\n####################################################################################################### \\n\\n\")\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ciclo \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      5\u001b[0m     opencsv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive - Instituto Politecnico de Castelo Branco\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m002_Learning\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m001_Pos_Graduacao\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCiclo 5 - Projeto Final\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjetoFinal-PosGraduacaoEngenhariaFinanceira\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdf_ciclo\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mciclo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_weekly.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mrun_models_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopencsv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 10\u001b[0m, in \u001b[0;36mrun_models_stats\u001b[1;34m(df, models_list, y)\u001b[0m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m df[model_columns]\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X)  \u001b[38;5;66;03m# Add a constant term to the predictors\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()  \u001b[38;5;66;03m# Fit the OLS model\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m####################################################################################################### \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:922\u001b[0m, in \u001b[0;36mOLS.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    919\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are not supported in OLS and will be ignored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception will be raised in the next version.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    921\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(msg, ValueWarning)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys:\n\u001b[0;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_keys\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:748\u001b[0m, in \u001b[0;36mWLS.__init__\u001b[1;34m(self, endog, exog, weights, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m nobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    751\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\regression\\linear_model.py:202\u001b[0m, in \u001b[0;36mRegressionModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRegressionModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpinv_wexog: Float64Array \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_attr\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinv_wexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwendog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwexog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[1;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[0;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[1;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Rui Caseiro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\base\\data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[1;34m(self, hasconst)\u001b[0m\n\u001b[0;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[1;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "\n",
    "models_list = [model1a, model1b]\n",
    "y = opencsv[\"BTC_USD\"]\n",
    "\n",
    "for ciclo in range(1, 5):\n",
    "    opencsv = pd.read_csv(rf\"D:\\OneDrive - Instituto Politecnico de Castelo Branco\\002_Learning\\001_Pos_Graduacao\\Ciclo 5 - Projeto Final\\ProjetoFinal-PosGraduacaoEngenhariaFinanceira\\df_ciclo{ciclo}_weekly.csv\", sep=\",\")\n",
    "\n",
    "    \n",
    "    run_models_stats(opencsv, models_list, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all params \n",
    "dir(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homocesdasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# https://www.geeksforgeeks.org/how-to-perform-a-breusch-pagan-test-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normality of Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: The residuals should be approximately normally distributed.\n",
    "\n",
    "Test:\n",
    "Q-Q Plot: Compare the quantiles of residuals to a normal distribution. If residuals are normal, the points will lie approximately on the 45-degree line.\n",
    "\n",
    "Shapiro-Wilk Test or Kolmogorov-Smirnov Test: Statistical tests for normality of residuals.\n",
    "\n",
    "Transformation: If residuals are not normally distributed, consider transforming the dependent variable or using robust regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independence of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Assumption: The residuals (errors) should be independent of each other.\n",
    "\n",
    "Test:\n",
    "\n",
    "Durbin-Watson Test: Detects the presence of autocorrelation in residuals, especially in time series data.\n",
    "\n",
    "Plot Residuals vs. Time: For time series data, plot residuals against time to detect patterns or autocorrelation.\n",
    "\n",
    "Transformation:\n",
    "Add Lagged Variables: For time series, include lagged values of the dependent variable as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Omitted Variable Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: All relevant independent variables are included in the model.\n",
    "\n",
    "Test:\n",
    "\n",
    "Ramsey RESET Test: Checks for omitted variables by testing for non-linearity in the model.\n",
    "\n",
    "Remedies:\n",
    "\n",
    "Include Relevant Variables: Ensure all theoretically important variables are included in the model.\n",
    "Use Model Selection Criteria: Such as AIC or BIC to guide variable selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de Multicolinearidade\n",
    "\n",
    "\n",
    "Como você tem muitas variáveis, é importante verificar a multicolinearidade, especialmente porque as variáveis acumuladas podem estar altamente correlacionadas entre si. Testes como o VIF (Variance Inflation Factor) podem ajudar a identificar problemas.\n",
    "\n",
    "Multicollinearity describes the state where the independent variables used in a study exhibit a strong relationship with each other. This can pose a problem in many cases as you would normally want your independent variables to be… independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "\n",
    "#find design matrix for linear regression model using 'rating' as response variable \n",
    "y, X = dmatrices('BTC_USD ~ Nr_Transactions + L1.USD_OnChain_Volume + L1.BTC_Supply + L1.Mining_Difficulty', data=df_model, return_type='dataframe')\n",
    "\n",
    "#calculate VIF for each explanatory variable\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "#view VIF for each explanatory variable \n",
    "vif\n",
    "\n",
    "\n",
    "#       Interpreting the VIF Values:\n",
    "#       VIF < 5: Generally considered acceptable, indicating low to moderate multicollinearity.\n",
    "#       VIF between 5 and 10: Indicates moderate to high multicollinearity, which may be problematic, but not necessarily requiring immediate removal.\n",
    "#       VIF > 10: Strong multicollinearity, typically suggesting that the variable should be considered for removal or that further investigation is needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
